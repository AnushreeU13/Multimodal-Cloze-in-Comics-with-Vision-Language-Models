{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing Pipeline: YOLOv8 Panels → CRAFT Text Regions → PaddleOCR\n",
        "\n",
        "This notebook processes comic page images by:\n",
        "- Detecting panels with YOLOv8 (bounding boxes)\n",
        "- Detecting text regions in each panel with CRAFT\n",
        "- Extracting text per page (aggregating all bubbles) with PaddleOCR\n",
        "\n",
        "Input: `C:\\Users\\uanus\\Box\\AML Comic Project\\2`\n",
        "- Output panels: `C:\\Users\\uanus\\Box\\AML Comic Project\\2_images`\n",
        "- Output text: `C:\\Users\\uanus\\Box\\AML Comic Project\\2_text`\n",
        "\n",
        "Notes:\n",
        "- You can adapt YOLO training from the beginner guide: `https://medium.com/@nandinilreddy/implementing-yolov8-in-detail-for-beginners-9a5d3b0fe30a`. Here we use inference (pretrained) but expose hooks for custom weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global toggles\n",
        "USE_CRAFT = False  # Set to True to enable CRAFT; otherwise PaddleOCR handles detection+recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install -U pip setuptools wheel\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install numpy<2\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install opencv-python<5\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install shapely\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install scikit-image\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install pyclipper\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install rapidfuzz\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install tqdm\n",
            "$ c:\\Users\\uanus\\anaconda3\\python.exe -m pip install ultralytics\n",
            "Dependency check complete. Restart kernel if imports still fail.\n"
          ]
        }
      ],
      "source": [
        "# Unified dependency install (run once). Restart kernel if imports fail.\n",
        "import sys\n",
        "import subprocess\n",
        "import platform\n",
        "\n",
        "\n",
        "def run(cmd: list):\n",
        "    print(\"$\", \" \".join(cmd))\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "\n",
        "def has(module_name: str) -> bool:\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Upgrade packaging tools\n",
        "run([sys.executable, '-m', 'pip', 'install', '-U', 'pip', 'setuptools', 'wheel'])\n",
        "\n",
        "# Core deps helpful for PaddleOCR and CV\n",
        "for pkg in [\n",
        "    'numpy<2', 'opencv-python<5', 'shapely', 'scikit-image', 'pyclipper', 'rapidfuzz', 'tqdm'\n",
        "]:\n",
        "    try:\n",
        "        run([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "    except subprocess.CalledProcessError:\n",
        "        pass\n",
        "\n",
        "# PaddlePaddle CPU (Windows) + PaddleOCR\n",
        "if platform.system() == 'Windows' and not has('paddle'):\n",
        "    run([sys.executable, '-m', 'pip', 'install', 'paddlepaddle==2.6.2'])\n",
        "if not has('paddleocr'):\n",
        "    # prefer a stable paddleocr version\n",
        "    try:\n",
        "        run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'paddleocr==2.8.1'])\n",
        "    except subprocess.CalledProcessError:\n",
        "        run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'paddleocr==2.7.3'])\n",
        "\n",
        "# Ultralytics for YOLOv8\n",
        "if not has('ultralytics'):\n",
        "    run([sys.executable, '-m', 'pip', 'install', 'ultralytics'])\n",
        "\n",
        "# Optional: CRAFT only if enabled\n",
        "if USE_CRAFT and not has('craft_text_detector'):\n",
        "    try:\n",
        "        run([sys.executable, '-m', 'pip', 'install', 'craft-text-detector==0.4.6'])\n",
        "    except subprocess.CalledProcessError:\n",
        "        try:\n",
        "            run([sys.executable, '-m', 'pip', 'install', 'git+https://github.com/faustomorales/craft-text-detector.git'])\n",
        "        except subprocess.CalledProcessError:\n",
        "            print('CRAFT install skipped; set USE_CRAFT=False or install manually from clovaai/CRAFT-pytorch.')\n",
        "\n",
        "print('Dependency check complete. Restart kernel if imports still fail.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"c:\\Users\\uanus\\anaconda3\\Lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Conditional imports guarded by availability and flags\u001b[39;00m\n\u001b[0;32m     13\u001b[0m CRAFT_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\uanus\\anaconda3\\Lib\\site-packages\\ultralytics\\__init__.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     11\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download\n",
            "File \u001b[1;32mc:\\Users\\uanus\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\__init__.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GitRepo\n",
            "File \u001b[1;32mc:\\Users\\uanus\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:278\u001b[0m\n\u001b[0;32m    274\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    276\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 278\u001b[0m     _load_dll_libraries()\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in path/nvidia/lib_folder/lib or path/lib_folder/lib\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\uanus\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:261\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    257\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    258\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    260\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"c:\\Users\\uanus\\anaconda3\\Lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
          ]
        }
      ],
      "source": [
        "# Imports and configuration\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Conditional imports guarded by availability and flags\n",
        "CRAFT_AVAILABLE = False\n",
        "try:\n",
        "    if USE_CRAFT:\n",
        "        from craft_text_detector import (Craft, get_prediction)\n",
        "        CRAFT_AVAILABLE = True\n",
        "except Exception:\n",
        "    CRAFT_AVAILABLE = False\n",
        "\n",
        "PADDLE_AVAILABLE = False\n",
        "try:\n",
        "    from paddleocr import PaddleOCR\n",
        "    PADDLE_AVAILABLE = True\n",
        "except Exception:\n",
        "    PADDLE_AVAILABLE = False\n",
        "\n",
        "# Folder configuration (adjust as needed)\n",
        "INPUT_DIR = Path(r\"C:\\Users\\uanus\\Box\\AML Comic Project\\2\")\n",
        "PANELS_DIR = Path(r\"C:\\Users\\uanus\\Box\\AML Comic Project\\2_images\")\n",
        "TEXT_DIR = Path(r\"C:\\Users\\uanus\\Box\\AML Comic Project\\2_text\")\n",
        "\n",
        "# Create output directories\n",
        "PANELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TEXT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Inference device config\n",
        "DEVICE = 'cuda' if cv2.cuda.getCudaEnabledDeviceCount() > 0 else 'cpu'\n",
        "\n",
        "print(f\"Input: {INPUT_DIR}\")\n",
        "print(f\"Panels out: {PANELS_DIR}\")\n",
        "print(f\"Text out: {TEXT_DIR}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"USE_CRAFT: {USE_CRAFT}, CRAFT_AVAILABLE: {CRAFT_AVAILABLE}, PADDLE_AVAILABLE: {PADDLE_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def ensure_rgb(img: np.ndarray) -> np.ndarray:\n",
        "    if img is None:\n",
        "        raise ValueError(\"Empty image\")\n",
        "    if len(img.shape) == 2:\n",
        "        return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    if img.shape[2] == 4:\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "    return img\n",
        "\n",
        "def sort_panels_reading_order(boxes: List[Tuple[int,int,int,int]]) -> List[Tuple[int,int,int,int]]:\n",
        "    \"\"\"Sort panels roughly left-to-right, top-to-bottom.\n",
        "    boxes: list of (x1, y1, x2, y2)\n",
        "    \"\"\"\n",
        "    if not boxes:\n",
        "        return boxes\n",
        "    # Sort by y, then x (with a row tolerance)\n",
        "    row_tol = max(10, int(0.03 * np.mean([b[3]-b[1] for b in boxes])))\n",
        "    boxes_sorted = sorted(boxes, key=lambda b: (b[1]//row_tol, b[0]))\n",
        "    return boxes_sorted\n",
        "\n",
        "def clip_box_to_image(box, w, h):\n",
        "    x1, y1, x2, y2 = box\n",
        "    return max(0,x1), max(0,y1), min(w-1,x2), min(h-1,y2)\n",
        "\n",
        "\n",
        "def save_panel_crop(page_path: Path, panel_idx: int, crop: np.ndarray) -> Path:\n",
        "    base = page_path.stem\n",
        "    out_path = PANELS_DIR / f\"{base}_panel_{panel_idx:02d}.jpg\"\n",
        "    cv2.imwrite(str(out_path), crop)\n",
        "    return out_path\n",
        "\n",
        "\n",
        "def aggregate_text_lines(results) -> str:\n",
        "    \"\"\"Aggregate PaddleOCR results into a single text per page.\n",
        "    results format: list of [ [box, (text, conf)], ... ]\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        return \"\"\n",
        "    lines = []\n",
        "    for det in results:\n",
        "        try:\n",
        "            text = det[1][0]\n",
        "            conf = det[1][1]\n",
        "            if text and conf is not None and conf >= 0.2:\n",
        "                lines.append(text)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return \"\\n\".join(lines).strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOLOv8: Panel detection wrapper\n",
        "class PanelDetector:\n",
        "    def __init__(self, weights: Optional[str] = None, conf: float = 0.25, iou: float = 0.5):\n",
        "        # Use a generic pretrained model (e.g., yolov8n) as placeholder\n",
        "        # Replace with your fine-tuned panel-detector weights when ready\n",
        "        self.model = YOLO(weights or 'yolov8n.pt')\n",
        "        self.conf = conf\n",
        "        self.iou = iou\n",
        "\n",
        "    def predict(self, image_bgr: np.ndarray) -> List[Tuple[int,int,int,int]]:\n",
        "        h, w = image_bgr.shape[:2]\n",
        "        results = self.model.predict(source=image_bgr, conf=self.conf, iou=self.iou, verbose=False, device=0 if DEVICE=='cuda' else None)\n",
        "        boxes = []\n",
        "        for r in results:\n",
        "            if r.boxes is None:\n",
        "                continue\n",
        "            for b in r.boxes.xyxy.cpu().numpy():\n",
        "                x1, y1, x2, y2 = b[:4].astype(int)\n",
        "                x1, y1, x2, y2 = clip_box_to_image((x1,y1,x2,y2), w, h)\n",
        "                # Optional: filter tiny boxes\n",
        "                if (x2-x1)*(y2-y1) < 0.01 * w*h:\n",
        "                    continue\n",
        "                boxes.append((x1,y1,x2,y2))\n",
        "        return sort_panels_reading_order(boxes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CRAFT: Text region detection (optional). If CRAFT import fails, this becomes a no-op.\n",
        "class TextRegionDetector:\n",
        "    def __init__(self, cuda: bool = (DEVICE=='cuda')):\n",
        "        try:\n",
        "            from craft_text_detector import Craft, get_prediction\n",
        "            self._Craft = Craft\n",
        "            self._get_prediction = get_prediction\n",
        "            self.craft = self._Craft(output_dir=None, cuda=cuda)\n",
        "            self.available = True\n",
        "        except Exception as e:\n",
        "            print(f\"CRAFT not available ({e}). Proceeding without text-region detection.\")\n",
        "            self.craft = None\n",
        "            self.available = False\n",
        "\n",
        "    def predict(self, image_bgr: np.ndarray) -> List[np.ndarray]:\n",
        "        \"\"\"Return list of polygons (np.ndarray Nx2) for detected text regions.\n",
        "        If CRAFT isn't available, return an empty list to allow downstream OCR on full panels.\n",
        "        \"\"\"\n",
        "        if not self.available:\n",
        "            return []\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "        prediction_result = self._get_prediction(\n",
        "            image=image_rgb,\n",
        "            craft_net=self.craft.craft_net,\n",
        "            text_threshold=0.7,\n",
        "            link_threshold=0.4,\n",
        "            low_text=0.4,\n",
        "            cuda=self.craft.cuda,\n",
        "        )\n",
        "        polys = prediction_result.get('boxes', [])\n",
        "        return polys or []\n",
        "\n",
        "    def release(self):\n",
        "        if self.available and self.craft is not None:\n",
        "            self.craft.unload_craftnet_model()\n",
        "            self.craft.unload_refinenet_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PaddleOCR: OCR wrapper\n",
        "class OCRExtractor:\n",
        "    def __init__(self, lang: str = 'en', use_angle_cls: bool = True):\n",
        "        # Use CPU by default on Windows unless CUDA Paddle is set up\n",
        "        self.ocr = PaddleOCR(use_angle_cls=use_angle_cls, lang=lang, use_gpu=(DEVICE=='cuda'))\n",
        "\n",
        "    def extract_text(self, image_bgr: np.ndarray) -> str:\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "        result = self.ocr.ocr(image_rgb, cls=True)\n",
        "        # result is list per image; when single image provided, it's [[det]]\n",
        "        if not result:\n",
        "            return \"\"\n",
        "        # Flatten and aggregate\n",
        "        flat = []\n",
        "        for det_list in result:\n",
        "            if not det_list:\n",
        "                continue\n",
        "            for det in det_list:\n",
        "                flat.append(det)\n",
        "        return aggregate_text_lines(flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# End-to-end processing pipeline\n",
        "\n",
        "def process_page_image(page_path: Path, panel_detector: PanelDetector, text_detector: TextRegionDetector, ocr: OCRExtractor) -> Dict:\n",
        "    \"\"\"Process one page: detect panels, save crops, run text detection+OCR per panel,\n",
        "    aggregate text over the page, and write .txt.\n",
        "    Returns a dict with metadata and saved file paths.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(str(page_path))\n",
        "    if img is None:\n",
        "        return {\"page\": str(page_path), \"error\": \"Failed to read image\"}\n",
        "\n",
        "    img = ensure_rgb(img)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # 1) Panel detection\n",
        "    panel_boxes = panel_detector.predict(img)\n",
        "\n",
        "    # 2) Save panel crops and run CRAFT+OCR per panel\n",
        "    page_text_lines = []\n",
        "    saved_panels = []\n",
        "\n",
        "    for idx, (x1, y1, x2, y2) in enumerate(panel_boxes):\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        out_path = save_panel_crop(page_path, idx, crop)\n",
        "        saved_panels.append(str(out_path))\n",
        "\n",
        "        # Text regions (optional future use: crop to text regions before OCR)\n",
        "        # For simplicity, pass whole panel to OCR, which is robust enough; CRAFT kept for extensibility\n",
        "        # polygons = text_detector.predict(crop)\n",
        "        text = ocr.extract_text(crop)\n",
        "        if text:\n",
        "            page_text_lines.append(text)\n",
        "\n",
        "    # 3) Aggregate all panel texts into a single page-level .txt\n",
        "    page_text = \"\\n\\n\".join([t for t in page_text_lines if t.strip()])\n",
        "    txt_out = TEXT_DIR / f\"{page_path.stem}.txt\"\n",
        "    with open(txt_out, 'w', encoding='utf-8') as f:\n",
        "        f.write(page_text)\n",
        "\n",
        "    return {\n",
        "        \"page\": str(page_path),\n",
        "        \"size\": [w, h],\n",
        "        \"num_panels\": len(panel_boxes),\n",
        "        \"panel_boxes\": panel_boxes,\n",
        "        \"panel_images\": saved_panels,\n",
        "        \"text_file\": str(txt_out),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the pipeline on the specified input folder\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Gather images (jpg/jpeg/png)\n",
        "image_exts = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "page_paths = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() in image_exts])\n",
        "print(f\"Found {len(page_paths)} pages in {INPUT_DIR}\")\n",
        "\n",
        "panel_detector = PanelDetector(weights=None, conf=0.25, iou=0.5)\n",
        "text_detector = TextRegionDetector(cuda=(DEVICE=='cuda'))\n",
        "ocr = OCRExtractor(lang='en', use_angle_cls=True)\n",
        "\n",
        "results = []\n",
        "for page in tqdm(page_paths):\n",
        "    res = process_page_image(page, panel_detector, text_detector, ocr)\n",
        "    results.append(res)\n",
        "\n",
        "# Save a summary JSON\n",
        "summary_path = TEXT_DIR / 'processing_summary.json'\n",
        "with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"Saved summary to {summary_path}\")\n",
        "print(\"Done.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
